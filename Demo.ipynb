{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import job_scraper\n",
    "# from job_scraper import find_jobs_from, load_indeed_jobs_div, load_hinge_jobs_div\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'job_scraper' from 'C:\\\\Users\\\\lauwx1\\\\Desktop\\\\job-scraper\\\\job_scraper.py'>\n"
     ]
    }
   ],
   "source": [
    "print(job_scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_characs = ['titles', 'companies', 'links', 'date_listed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting jobs from Indeed.co.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_jobs_from('Indeed', 'data analyst', 'california', desired_characs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting jobs from Hinge Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_indeed_jobs_div('data analyst','california')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hinge_jobs_div(commitment='Full-time', team='Engineering'):\n",
    "    getVars = {'commitment': commitment, 'team': team}\n",
    "    url = ('https://jobs.lever.co/hingehealth?' + urllib.parse.urlencode(getVars))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    # job_soup = soup.find(id=\"resultsCol\")\n",
    "    # job_soup = soup.find(data-qa=\"posting-name\")\n",
    "#     job_soup = soup.find_all('h5') ##this returns all the job titles/names, but try to get the LINKS posted as well\n",
    "#     job_soup = soup.find_all('a', class_=\"posting-title\")##trying to get the link for job\n",
    "    job_soup = soup.find(class_=\"postings-group\")\n",
    "    return job_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commitment=Full-time&team=Engineering'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getVars = {'commitment': 'Full-time', 'team': 'Engineering'}\n",
    "# urllib.parse.urlencode(getVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_jobs_from('Hinge', 'data analyst', 'california', desired_characs)\n",
    "test_soup = load_hinge_jobs_div(commitment='Full-time', team='Engineering') ## find_all funct returns a <class 'bs4.element.ResultSet'>\n",
    "# page = requests.get('https://jobs.lever.co/hingehealth?commitment=Full-time&team=Engineering')\n",
    "# soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "# soup ##somehow when i run the stuff inside the function it works, but the call to the function won't work. its calling None??\n",
    "\n",
    "## basically try to find TITLE have it from h5 tag, and all the DATE_LISTED associated with that job\n",
    "##title is under h5 tag data-qa = posting-name\n",
    "## link is under a class = posting-title href.. now to extract this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract info from soup\n",
    "def extract_job_information_indeed(job_soup, desired_characs):\n",
    "    job_elems = job_soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "\n",
    "    cols = []\n",
    "    extracted_info = []\n",
    "\n",
    "    if 'titles' in desired_characs:\n",
    "        titles = []\n",
    "        cols.append('titles')\n",
    "        for job_elem in job_elems:\n",
    "            titles.append(extract_job_title_indeed(job_elem))\n",
    "        extracted_info.append(titles)\n",
    "\n",
    "#     if 'companies' in desired_characs:\n",
    "#         companies = []\n",
    "#         cols.append('companies')\n",
    "#         for job_elem in job_elems:\n",
    "#             companies.append(extract_company_indeed(job_elem))\n",
    "#         extracted_info.append(companies)\n",
    "\n",
    "    if 'links' in desired_characs:\n",
    "        links = []\n",
    "        cols.append('links')\n",
    "        for job_elem in job_elems:\n",
    "            links.append(extract_link_indeed(job_elem))\n",
    "        extracted_info.append(links)\n",
    "\n",
    "#     if 'date_listed' in desired_characs:\n",
    "#         dates = []\n",
    "#         cols.append('date_listed')\n",
    "#         for job_elem in job_elems:\n",
    "#             dates.append(extract_date_indeed(job_elem))\n",
    "#         extracted_info.append(dates)\n",
    "\n",
    "    jobs_list = {}\n",
    "\n",
    "    for j in range(len(cols)):\n",
    "        jobs_list[cols[j]] = extracted_info[j]\n",
    "\n",
    "    num_listings = len(extracted_info[0])\n",
    "\n",
    "    return jobs_list, num_listings\n",
    "\n",
    "def extract_job_title_hinge(job_elem):\n",
    "    title_elem = job_elem.find('h5')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    "\n",
    "def extract_link_hinge(job_elem):\n",
    "    link = job_elem.find('a')['href']\n",
    "#     link = 'www.Indeed.co.uk/' + link\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"posting-title\" href=\"https://jobs.lever.co/hingehealth/ac1ae9df-8d57-415b-98dd-c27668ed91f2\"><h5 data-qa=\"posting-name\">Data Engineer</h5><div class=\"posting-categories\"><span class=\"sort-by-location posting-category small-category-label\" href=\"#\">San Francisco, Portland, Denver, Austin, Los Angeles, Seattle, New York</span><span class=\"sort-by-team posting-category small-category-label\" href=\"#\">Engineering</span></div></a>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_elem.find_all('a', class_='posting-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test extract title function\n",
    "type(test_soup)\n",
    "job_elems = test_soup.find_all('a', class_='posting-title')\n",
    "type(job_elems)\n",
    "titles = []\n",
    "extracted_info = []\n",
    "for job_elem in job_elems:\n",
    "    titles.append(extract_job_title_hinge(job_elem))\n",
    "extracted_info.append(titles)\n",
    "# extract_job_title_hinge(job_elems)\n",
    "\n",
    "\n",
    "##test extract link function\n",
    "links = []\n",
    "# for job_elem in job_elems:\n",
    "#     links.append(extract_link_hinge(job_elem))\n",
    "# extracted_info.append(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Data Engineer',\n",
       "  'Director of Application Engineering, Core App',\n",
       "  'Engineering Manager (Platform)',\n",
       "  'Senior Software Engineer (Backend)',\n",
       "  'Senior Software Engineer (Data Focus)',\n",
       "  'Senior Software Engineer (Front End)',\n",
       "  'Senior Software Engineer (Full-Stack)',\n",
       "  'Senior Software Engineer (Internal Tooling)',\n",
       "  'Site Reliability Engineer',\n",
       "  'Technical Lead']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##compare results to the indeed query/function\n",
    "extracted_info\n",
    "# job_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indeed_jobs_div(job_title, location):\n",
    "    getVars = {'q': job_title, 'l': location, 'fromage': 'last', 'sort': 'date'}\n",
    "    url = ('https://www.indeed.com/jobs?' + urllib.parse.urlencode(getVars))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    job_soup = soup.find(id=\"resultsCol\")\n",
    "    return job_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=\"data scientist\"\n",
    "location = \"california\"\n",
    "load_indeed_jobs_div(job_title,location) ## returns a <class 'bs4.element.Tag'> from \"find\" function\n",
    "type(load_indeed_jobs_div(job_title,location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting jobs from CWjobs.co.uk (using Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_jobs_from('CWjobs', 'data scientist', 'london', desired_characs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "thesis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
